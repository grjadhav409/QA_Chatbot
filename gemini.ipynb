{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "import urllib\n",
    "import warnings\n",
    "from pathlib import Path as p\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/ganeshjadhav/Desktop/ITIL_projects/Document_retrival_gpt/data/practitioners_guide_to_mlops_whitepaper.pdf',\n",
       " <http.client.HTTPMessage at 0x14ccf5c60>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = p.cwd() / \"data\"\n",
    "p(data_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pdf_url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
    "pdf_file = str(p(data_folder, pdf_url.split(\"/\")[-1]))\n",
    "\n",
    "urllib.request.urlretrieve(pdf_url, pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(pdf_file)\n",
    "pages = pdf_loader.load_and_split()\n",
    "# print(pages[3].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total words in the context:  55545\n"
     ]
    }
   ],
   "source": [
    "context = \"\\n\".join(str(p.page_content) for p in pages[:30])\n",
    "print(\"The total words in the context: \", len(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
    "                    not contained in the context, say \"answer not available in context\" \\n\\n\n",
    "                    Context: \\n {context}?\\n\n",
    "                    Question: \\n {question} \\n\n",
    "                    Answer:\n",
    "                  \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=0)\n",
    "context = \"\\n\\n\".join(str(p.page_content) for p in pages)\n",
    "texts = text_splitter.split_text(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = Chroma.from_texts(texts, embeddings).as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Describe data management and feature management systems.\"\n",
    "docs = vector_index.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_answer = stuff_chain(\n",
    "    {\"input_documents\": docs, \"question\": question}, return_only_outputs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Data management and feature management systems provide a unified repository for ML features and datasets. This repository allows multiple uses in the MLOps environment, including experimentation, batch serving, continuous training, batch prediction, and real-time prediction. Feature management systems help data scientists and researchers discover and reuse available feature sets for their entities instead of re-creating them. This can save time and prevent inconsistent definitions and instances of the same data entities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(stuff_answer['output_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
